{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative AI Output Evaluation Pipeline\n",
    "## Overview\n",
    "This document provides both documentation and complete implementation of a comprehensive pipeline for evaluating Generative AI outputs across multiple dimensions including bias, fairness, and quality. The pipeline is designed for educational purposes, helping students understand how to systematically assess AI-generated content.\n",
    "\n",
    "\n",
    "## Installation\n",
    "### Prerequisites\n",
    "Ensure you have Python 3.8+ installed. The project dependencies are listed in requirements.txt:\n",
    "```bash \n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Next, download the correct spaCy model:\n",
    "```bash\n",
    "python -m spacy download en_core_web_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(['punkt', 'averaged_perceptron_tagger', 'stopwords', 'wordnet'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "\n",
    "class FairnessEvaluator:\n",
    "    def evaluate_demographic_parity(self, \n",
    "                                  predictions: List[bool], \n",
    "                                  demographics: List[str]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Measures whether predictions are independent of demographic group.\n",
    "        A difference of 0 indicates perfect demographic parity.\n",
    "        \n",
    "        Args:\n",
    "            predictions: List of model predictions (True/False)\n",
    "            demographics: List of demographic group labels\n",
    "        \"\"\"\n",
    "        # Calculate prediction rate for each group\n",
    "        group_rates = {}\n",
    "        for group in set(demographics):\n",
    "            group_preds = [p for p, d in zip(predictions, demographics) if d == group]\n",
    "            group_rates[group] = sum(group_preds) / len(group_preds)\n",
    "            \n",
    "        # Calculate maximum difference between groups\n",
    "        max_diff = max(group_rates.values()) - min(group_rates.values())\n",
    "        \n",
    "        return {\n",
    "            'group_rates': group_rates,\n",
    "            'demographic_parity_difference': max_diff\n",
    "        }\n",
    "    \n",
    "    def evaluate_equalized_odds(self,\n",
    "                              predictions: List[bool],\n",
    "                              demographics: List[str],\n",
    "                              ground_truth: List[bool]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Measures whether predictions have equal true/false positive rates across groups.\n",
    "        A difference of 0 indicates perfect equalized odds.\n",
    "        \n",
    "        Args:\n",
    "            predictions: List of model predictions (True/False)\n",
    "            demographics: List of demographic group labels\n",
    "            ground_truth: List of actual outcomes (True/False)\n",
    "        \"\"\"\n",
    "        group_metrics = {}\n",
    "        \n",
    "        for group in set(demographics):\n",
    "            # Get indices for this group\n",
    "            group_idx = [i for i, d in enumerate(demographics) if d == group]\n",
    "            \n",
    "            # Calculate TPR and FPR for this group\n",
    "            true_pos = sum(1 for i in group_idx \n",
    "                         if predictions[i] and ground_truth[i])\n",
    "            false_pos = sum(1 for i in group_idx \n",
    "                          if predictions[i] and not ground_truth[i])\n",
    "            actual_pos = sum(1 for i in group_idx if ground_truth[i])\n",
    "            actual_neg = sum(1 for i in group_idx if not ground_truth[i])\n",
    "            \n",
    "            tpr = true_pos / actual_pos if actual_pos > 0 else 0\n",
    "            fpr = false_pos / actual_neg if actual_neg > 0 else 0\n",
    "            \n",
    "            group_metrics[group] = {'TPR': tpr, 'FPR': fpr}\n",
    "        \n",
    "        # Calculate differences between groups\n",
    "        tpr_diff = max(m['TPR'] for m in group_metrics.values()) - \\\n",
    "                  min(m['TPR'] for m in group_metrics.values())\n",
    "        fpr_diff = max(m['FPR'] for m in group_metrics.values()) - \\\n",
    "                  min(m['FPR'] for m in group_metrics.values())\n",
    "        \n",
    "        return {\n",
    "            'group_metrics': group_metrics,\n",
    "            'TPR_difference': tpr_diff,\n",
    "            'FPR_difference': fpr_diff,\n",
    "            'equalized_odds_difference': (tpr_diff + fpr_diff) / 2\n",
    "        }\n",
    "    \n",
    "    def evaluate_equal_opportunity(self,\n",
    "                                 predictions: List[bool],\n",
    "                                 demographics: List[str],\n",
    "                                 ground_truth: List[bool]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Measures whether true positive rates are equal across groups.\n",
    "        A difference of 0 indicates perfect equal opportunity.\n",
    "        \n",
    "        Args:\n",
    "            predictions: List of model predictions (True/False)\n",
    "            demographics: List of demographic group labels\n",
    "            ground_truth: List of actual outcomes (True/False)\n",
    "        \"\"\"\n",
    "        group_tpr = {}\n",
    "        \n",
    "        for group in set(demographics):\n",
    "            # Get indices for this group\n",
    "            group_idx = [i for i, d in enumerate(demographics) if d == group]\n",
    "            \n",
    "            # Calculate TPR for this group\n",
    "            true_pos = sum(1 for i in group_idx \n",
    "                         if predictions[i] and ground_truth[i])\n",
    "            actual_pos = sum(1 for i in group_idx if ground_truth[i])\n",
    "            \n",
    "            tpr = true_pos / actual_pos if actual_pos > 0 else 0\n",
    "            group_tpr[group] = tpr\n",
    "        \n",
    "        # Calculate maximum difference in TPR between groups\n",
    "        tpr_diff = max(group_tpr.values()) - min(group_tpr.values())\n",
    "        \n",
    "        return {\n",
    "            'group_TPR': group_tpr,\n",
    "            'equal_opportunity_difference': tpr_diff\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage\n",
    "Here's how to use the evaluation pipeline:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographic Parity - Measures whether the model's positive predictions are equal across demographic groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = FairnessEvaluator()\n",
    "\n",
    "# Example data from a resume screening system\n",
    "predictions = [\n",
    "    True,  # Selected\n",
    "    False, # Not selected\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    True\n",
    "]\n",
    "\n",
    "demographics = [\n",
    "    \"group_A\",\n",
    "    \"group_A\",\n",
    "    \"group_A\",\n",
    "    \"group_B\",\n",
    "    \"group_B\",\n",
    "    \"group_B\"\n",
    "]\n",
    "\n",
    "# Evaluate demographic parity\n",
    "parity_results = evaluator.evaluate_demographic_parity(predictions, demographics)\n",
    "print(\"\\nDemographic Parity Results:\")\n",
    "print(f\"Selection rates by group: {parity_results['group_rates']}\")\n",
    "print(f\"Maximum difference between groups: {parity_results['demographic_parity_difference']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equalized Odds Parity - Ensures equal true positive and false positive rates across groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data from a loan approval system\n",
    "predictions = [True, True, False, True, False, False]  # Approved/Not approved\n",
    "demographics = [\"group_A\", \"group_A\", \"group_A\", \"group_B\", \"group_B\", \"group_B\"]\n",
    "ground_truth = [True, True, False, True, True, False]  # Actually creditworthy\n",
    "\n",
    "# Evaluate equalized odds\n",
    "odds_results = evaluator.evaluate_equalized_odds(predictions, demographics, ground_truth)\n",
    "print(\"\\nEqualized Odds Results:\")\n",
    "print(\"Performance metrics by group:\", odds_results['group_metrics'])\n",
    "print(f\"TPR difference between groups: {odds_results['TPR_difference']}\")\n",
    "print(f\"FPR difference between groups: {odds_results['FPR_difference']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equal Opportunity Parity - Ensures equal true positive rates across groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data from job candidate assessment\n",
    "predictions = [True, False, True, False, True, False]  # Selected/Not selected\n",
    "demographics = [\"group_A\", \"group_A\", \"group_A\", \"group_B\", \"group_B\", \"group_B\"]\n",
    "ground_truth = [True, False, True, True, True, False]  # Actually qualified\n",
    "\n",
    "# Evaluate equal opportunity\n",
    "opportunity_results = evaluator.evaluate_equal_opportunity(\n",
    "    predictions, demographics, ground_truth\n",
    ")\n",
    "print(\"\\nEqual Opportunity Results:\")\n",
    "print(f\"True Positive Rates by group: {opportunity_results['group_TPR']}\")\n",
    "print(f\"Difference in opportunity: {opportunity_results['equal_opportunity_difference']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Evaluation with All Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_metrics(predictions, demographics, ground_truth):\n",
    "    \"\"\"Evaluate all fairness metrics at once.\"\"\"\n",
    "    evaluator = FairnessEvaluator()\n",
    "    \n",
    "    results = {\n",
    "        'demographic_parity': evaluator.evaluate_demographic_parity(\n",
    "            predictions, demographics\n",
    "        ),\n",
    "        'equalized_odds': evaluator.evaluate_equalized_odds(\n",
    "            predictions, demographics, ground_truth\n",
    "        ),\n",
    "        'equal_opportunity': evaluator.evaluate_equal_opportunity(\n",
    "            predictions, demographics, ground_truth\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage with medical diagnosis system data\n",
    "predictions = [True, True, False, True, False, True]  # Diagnosed condition\n",
    "demographics = [\"group_A\", \"group_A\", \"group_A\", \"group_B\", \"group_B\", \"group_B\"]\n",
    "ground_truth = [True, True, False, True, False, False]  # Actual condition\n",
    "\n",
    "results = evaluate_all_metrics(predictions, demographics, ground_truth)\n",
    "\n",
    "print(\"\\nComprehensive Fairness Evaluation:\")\n",
    "print(\"\\nDemographic Parity:\")\n",
    "print(f\"Group Rates: {results['demographic_parity']['group_rates']}\")\n",
    "print(f\"Difference: {results['demographic_parity']['demographic_parity_difference']}\")\n",
    "\n",
    "print(\"\\nEqualized Odds:\")\n",
    "print(f\"Group Metrics: {results['equalized_odds']['group_metrics']}\")\n",
    "print(f\"Overall Difference: {results['equalized_odds']['equalized_odds_difference']}\")\n",
    "\n",
    "print(\"\\nEqual Opportunity:\")\n",
    "print(f\"Group TPR: {results['equal_opportunity']['group_TPR']}\")\n",
    "print(f\"Difference: {results['equal_opportunity']['equal_opportunity_difference']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Metrics:\n",
    "\n",
    "### Demographic Parity\n",
    "\n",
    "Measures if predictions are independent of demographic group\n",
    "Perfect parity = 0.0 difference between groups\n",
    "Higher differences indicate potential bias\n",
    "\n",
    "\n",
    "### Equalized Odds\n",
    "\n",
    "Measures if both TPR and FPR are equal across groups\n",
    "Perfect equality = 0.0 difference in both rates\n",
    "Helps identify if model accuracy varies by group\n",
    "\n",
    "\n",
    "### Equal Opportunity\n",
    "\n",
    "Measures if TPR is equal across groups\n",
    "Perfect equality = 0.0 difference in TPR\n",
    "Focuses on fair treatment of qualified candidates\n",
    "\n",
    "\n",
    "\n",
    "**Note**: Remember that these metrics often trade off against each other, and the appropriate balance depends on your specific use case and fairness goals."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps to Consider\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "Clean and normalize input text\n",
    "Handle edge cases (empty strings, very long texts)\n",
    "Validate demographic information\n",
    "\n",
    "\n",
    "## Evaluation Strategy\n",
    "\n",
    "Use multiple metrics for each dimension\n",
    "Consider context-specific requirements\n",
    "Document assumptions and limitations\n",
    "\n",
    "\n",
    "## Result Interpretation\n",
    "\n",
    "Consider relative scores rather than absolute values\n",
    "Look for patterns across multiple outputs\n",
    "Account for domain-specific considerations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f57ffd79f07881f90ffd84d1ee449596c2bc3e88fee236dc006178dc960802e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
