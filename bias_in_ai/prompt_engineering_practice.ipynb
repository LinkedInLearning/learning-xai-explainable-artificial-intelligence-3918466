{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sLdB3cIfPrt"
      },
      "source": [
        "# Prompt Engineering: A Structured Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKxMDKkAfPru"
      },
      "source": [
        "## Overview\n",
        "This Jupyter notebook provides a structured approach to prompt engineering using NLTK, focusing on generating clear, neutral, and inclusive content."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyX-0CQHfPru"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "- Python 3.8 or higher\n",
        "- Jupyter Notebook/Lab environment\n",
        "- Basic understanding of Python and API interactions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check our python version in bash/terminal\n",
        "# !python3 --version"
      ],
      "metadata": {
        "id": "7yPCwjdg1GEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ijI-IabfPrv"
      },
      "source": [
        "## Python Environment Setup\n",
        "Create a new virtual environment and install the required packages in bash:\n",
        "```bash\n",
        "python -m venv nltk-env\n",
        "source nltk-env/bin/activate  # On Windows: nltk-env\\Scripts\\activate\n",
        "pip install -r requirements.txt\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNWcuQe1fmYe"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHyPrTZ2jpLA"
      },
      "outputs": [],
      "source": [
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eRmm5frloNa"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUWd0UxmmLRX"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdTPQUZMfPrw"
      },
      "source": [
        "# Code Implementation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "NLTK-based Prompt Engineering Module\n",
        "\n",
        "This module provides utilities for analyzing text using NLTK and\n",
        "implementing structured prompt engineering approaches with bias detection.\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import logging\n",
        "from typing import Dict, Any, List, Optional, Union\n",
        "from datetime import datetime\n",
        "import re\n",
        "from pathlib import Path\n",
        "import time\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download required NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "class NLTKPromptEngineer:\n",
        "    \"\"\"A class for managing prompt engineering with NLTK analysis.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the NLTKPromptEngineer class.\n",
        "        \"\"\"\n",
        "        self.history: List[Dict[str, Any]] = []\n",
        "\n",
        "        # Initialize NLTK analyzers\n",
        "        self.sia = SentimentIntensityAnalyzer()\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "\n",
        "        logging.info(\"NLTK Prompt Engineer initialized successfully\")\n",
        "\n",
        "    def create_structured_prompt(\n",
        "        self,\n",
        "        task: str,\n",
        "        context: str = \"\",\n",
        "        constraints: List[str] = None,\n",
        "        examples: List[Dict[str, str]] = None\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Create a structured prompt following best practices.\n",
        "\n",
        "        Args:\n",
        "            task (str): Main task description\n",
        "            context (str): Additional context for the task\n",
        "            constraints (List[str]): List of constraints to apply\n",
        "            examples (List[Dict[str, str]]): List of example input/output pairs\n",
        "\n",
        "        Returns:\n",
        "            str: Formatted text prompt\n",
        "        \"\"\"\n",
        "        constraints = constraints or []\n",
        "        examples = examples or []\n",
        "\n",
        "        # Build prompt content\n",
        "        prompt_text = \"# Task\\n\" + task\n",
        "\n",
        "        if context:\n",
        "            prompt_text += \"\\n\\n# Context\\n\" + context\n",
        "\n",
        "        if constraints:\n",
        "            prompt_text += \"\\n\\n# Constraints:\\n\"\n",
        "            prompt_text += \"\\n\".join(f\"- {c}\" for c in constraints)\n",
        "\n",
        "        # Add examples\n",
        "        if examples:\n",
        "            prompt_text += \"\\n\\n# Examples:\\n\"\n",
        "            for example in examples:\n",
        "                if \"input\" in example:\n",
        "                    prompt_text += f\"\\nInput: {example['input']}\\n\"\n",
        "                if \"output\" in example:\n",
        "                    prompt_text += f\"Output: {example['output']}\\n\"\n",
        "\n",
        "        return prompt_text\n",
        "\n",
        "    def analyze_text(\n",
        "        self,\n",
        "        text: str,\n",
        "        analyze_sentiment: bool = True,\n",
        "        analyze_bias: bool = True,\n",
        "        analyze_complexity: bool = True\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Analyze text using NLTK for various metrics.\n",
        "\n",
        "        Args:\n",
        "            text (str): Text to analyze\n",
        "            analyze_sentiment (bool): Whether to analyze sentiment\n",
        "            analyze_bias (bool): Whether to analyze bias\n",
        "            analyze_complexity (bool): Whether to analyze complexity\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Any]: Analysis metrics\n",
        "        \"\"\"\n",
        "        results = {}\n",
        "\n",
        "        # Basic text stats\n",
        "        words = word_tokenize(text)\n",
        "        sentences = sent_tokenize(text)\n",
        "\n",
        "        results[\"word_count\"] = len(words)\n",
        "        results[\"sentence_count\"] = len(sentences)\n",
        "        results[\"avg_words_per_sentence\"] = len(words) / len(sentences) if sentences else 0\n",
        "\n",
        "        # Sentiment analysis\n",
        "        if analyze_sentiment:\n",
        "            sentiment = self.sia.polarity_scores(text)\n",
        "            results[\"sentiment\"] = sentiment\n",
        "\n",
        "        # Bias analysis\n",
        "        if analyze_bias:\n",
        "            bias_scores = self._evaluate_bias(text)\n",
        "            results[\"bias\"] = bias_scores\n",
        "\n",
        "        # Text complexity\n",
        "        if analyze_complexity:\n",
        "            # Simple readability metrics\n",
        "            long_words = [w for w in words if len(w) > 6]\n",
        "            results[\"complexity\"] = {\n",
        "                \"long_word_ratio\": len(long_words) / len(words) if words else 0,\n",
        "                \"avg_word_length\": sum(len(w) for w in words) / len(words) if words else 0,\n",
        "            }\n",
        "\n",
        "        return results\n",
        "\n",
        "    # Pre-compiled regex patterns for bias evaluation\n",
        "    _bias_indicators = {\n",
        "        'gender_bias': {\n",
        "            'patterns': [\n",
        "                re.compile(r'\\b(he|his|him|gentleman|man|men)\\b(?!.*\\b(she|her|hers|lady|woman|women)\\b)', re.IGNORECASE),\n",
        "                re.compile(r'\\b(she|her|hers|lady|woman|women)\\b(?!.*\\b(he|his|him|gentleman|man|men)\\b)', re.IGNORECASE),\n",
        "                re.compile(r'\\b(businessman|businesswoman|chairman|chairwoman|spokesman|spokeswoman)\\b', re.IGNORECASE)\n",
        "            ],\n",
        "            'weight': 0.3\n",
        "        },\n",
        "        'racial_bias': {\n",
        "            'patterns': [\n",
        "                re.compile(r'\\b(normal|standard|regular|typical|default)(?=\\s+(person|people|individual|community))\\b', re.IGNORECASE),\n",
        "                re.compile(r'\\b(ethnic|minority|diverse)(?=\\s+only\\b)', re.IGNORECASE),\n",
        "            ],\n",
        "            'weight': 0.3\n",
        "        },\n",
        "        'age_bias': {\n",
        "            'patterns': [\n",
        "                re.compile(r'\\b(young|old|elderly|senior)(?=\\s+people\\b)', re.IGNORECASE),\n",
        "                re.compile(r'\\b(millennials|boomers|gen\\s+[xyz])\\b\\s+(?=\\b(are|always|never|typically)\\b)', re.IGNORECASE),\n",
        "            ],\n",
        "            'weight': 0.2\n",
        "        },\n",
        "        'socioeconomic_bias': {\n",
        "            'patterns': [\n",
        "                re.compile(r'\\b(poor|rich|wealthy|low-income|high-income)(?=\\s+people\\b)', re.IGNORECASE),\n",
        "                re.compile(r'\\b(educated|uneducated|privileged|underprivileged)\\b', re.IGNORECASE),\n",
        "            ],\n",
        "            'weight': 0.2\n",
        "        }\n",
        "    }\n",
        "\n",
        "    def _evaluate_bias(self, text: str) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Evaluate text for various types of bias using NLTK and regex.\n",
        "\n",
        "        Args:\n",
        "            text (str): Text to evaluate\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, float]: Bias scores for different bias types\n",
        "        \"\"\"\n",
        "        # Ensure text is a string\n",
        "        if not isinstance(text, str):\n",
        "            text = str(text)\n",
        "\n",
        "        bias_scores = {}\n",
        "        overall_bias = 0.0\n",
        "\n",
        "        for bias_type, config in self._bias_indicators.items():\n",
        "            type_score = 0\n",
        "            matches = []\n",
        "\n",
        "            for pattern in config['patterns']:\n",
        "                found_matches = pattern.findall(text)\n",
        "                matches.extend(found_matches)\n",
        "                if found_matches:\n",
        "                    type_score += len(found_matches) * 0.1\n",
        "\n",
        "            bias_scores[bias_type] = min(1.0, type_score)\n",
        "            overall_bias += bias_scores[bias_type] * config['weight']\n",
        "\n",
        "            # Store matched phrases for explanation\n",
        "            bias_scores[f\"{bias_type}_matches\"] = matches\n",
        "\n",
        "        bias_scores[\"overall\"] = min(1.0, overall_bias)\n",
        "        return bias_scores\n",
        "\n",
        "    def evaluate_text(\n",
        "        self,\n",
        "        text: str,\n",
        "        criteria: List[str]\n",
        "    ) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Evaluate the quality of text based on given criteria.\n",
        "\n",
        "        Args:\n",
        "            text (str): Text to evaluate\n",
        "            criteria (List[str]): List of evaluation criteria\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, float]: Evaluation scores\n",
        "        \"\"\"\n",
        "        # Ensure text is a string\n",
        "        if not isinstance(text, str):\n",
        "            text = str(text)\n",
        "\n",
        "        scores = {}\n",
        "\n",
        "        print(f\"Evaluating text on {len(criteria)} criteria...\")\n",
        "\n",
        "        for i, criterion in enumerate(criteria):\n",
        "            if criterion == \"bias\":\n",
        "                bias_results = self._evaluate_bias(text)\n",
        "                scores[criterion] = bias_results[\"overall\"]\n",
        "                # Add specific bias types\n",
        "                for bias_type in self._bias_indicators.keys():\n",
        "                    scores[f\"bias_{bias_type}\"] = bias_results[bias_type]\n",
        "            elif criterion == \"sentiment\":\n",
        "                sentiment = self.sia.polarity_scores(text)\n",
        "                scores[\"sentiment_positive\"] = sentiment[\"pos\"]\n",
        "                scores[\"sentiment_negative\"] = sentiment[\"neg\"]\n",
        "                scores[\"sentiment_neutral\"] = sentiment[\"neu\"]\n",
        "                scores[\"sentiment_compound\"] = sentiment[\"compound\"]\n",
        "            elif criterion == \"clarity\":\n",
        "                # Measure clarity based on sentence length, word complexity\n",
        "                words = word_tokenize(text)\n",
        "                sentences = sent_tokenize(text)\n",
        "                avg_sentence_length = len(words) / len(sentences) if sentences else 0\n",
        "                complex_words = [w for w in words if len(w) > 6 and w.lower() not in self.stop_words]\n",
        "                scores[\"clarity\"] = 1.0 - min(1.0, (len(complex_words) / len(words) * 1.5 +\n",
        "                                           (avg_sentence_length / 25.0)))\n",
        "            elif criterion == \"engagement\":\n",
        "                # Measure engagement based on question marks, imperative verbs, etc.\n",
        "                question_count = text.count(\"?\")\n",
        "                exclamation_count = text.count(\"!\")\n",
        "                second_person_count = len(re.findall(r'\\byou\\b|\\byour\\b', text, re.IGNORECASE))\n",
        "                engagement_score = min(1.0, (question_count * 0.2 + exclamation_count * 0.1 +\n",
        "                                          second_person_count * 0.05))\n",
        "                scores[\"engagement\"] = engagement_score\n",
        "            else:\n",
        "                # Default to a neutral score for unknown criteria\n",
        "                scores[criterion] = 0.5\n",
        "\n",
        "            print(f\"Evaluated {i+1}/{len(criteria)}: {criterion}\")\n",
        "\n",
        "        print(\"Evaluation complete!\")\n",
        "        return scores\n",
        "\n",
        "    def save_history(self, filepath: Union[str, Path]) -> None:\n",
        "        \"\"\"\n",
        "        Save interaction history to a JSON file.\n",
        "\n",
        "        Args:\n",
        "            filepath (Union[str, Path]): Path to save the history file\n",
        "        \"\"\"\n",
        "        print(f\"Saving history to {filepath}...\")\n",
        "        filepath = Path(filepath)\n",
        "        with filepath.open('w') as f:\n",
        "            json.dump(self.history, f, indent=2)\n",
        "        print(\"History saved successfully!\")"
      ],
      "metadata": {
        "id": "17QQ0zAkyE8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_nltk_bias_detection():\n",
        "    # Initialize the NLTK prompt engineer\n",
        "    engineer = NLTKPromptEngineer()\n",
        "\n",
        "    # Test various texts for bias\n",
        "    print(\"\\nTesting NLTK bias detection...\")\n",
        "\n",
        "    texts = [\n",
        "        # Gender bias\n",
        "        \"He is likely to excel in engineering roles due to his analytical thinking.\",\n",
        "        \"The ideal candidate for this nursing position should be nurturing and gentle like most women.\",\n",
        "        \"Men naturally perform better in mathematical and technical fields due to their logical minds.\",\n",
        "        \"Women are more suitable for administrative roles because they are detail-oriented and better at multitasking.\",\n",
        "\n",
        "        # Racial bias\n",
        "        \"Asian applicants are perfect for quantitative roles because they're naturally good at math.\",\n",
        "        \"Latino workers are ideal for physical labor positions due to their strong work ethic.\",\n",
        "        \"White executives tend to make better strategic decisions for American companies.\",\n",
        "        \"Black employees often struggle with professional communication in corporate environments.\",\n",
        "\n",
        "        # Age bias\n",
        "        \"Younger employees bring energy and tech-savviness that older workers simply cannot match.\",\n",
        "        \"Workers over 50 can't adapt to new technologies as quickly as millennials can.\",\n",
        "        \"We need young, fresh talent instead of outdated perspectives from baby boomers.\",\n",
        "        \"Recent graduates are more innovative than employees with decades of experience.\",\n",
        "\n",
        "        # Socio-economic bias\n",
        "        \"Candidates from prestigious universities are naturally more qualified for leadership roles.\",\n",
        "        \"Employees who speak with regional accents should be placed in back-office positions rather than client-facing roles.\",\n",
        "        \"People from affluent backgrounds have better soft skills required for management positions.\",\n",
        "        \"Workers from lower-income neighborhoods tend to have poorer work ethics and reliability issues.\"\n",
        "    ]\n",
        "\n",
        "    for i, text in enumerate(texts):\n",
        "        print(f\"\\nAnalyzing text {i+1}:\")\n",
        "        print(f\"Text: {text}\")\n",
        "        analysis = engineer.analyze_text(text)\n",
        "        print(f\"Word count: {analysis['word_count']}\")\n",
        "        print(f\"Bias score: {analysis['bias']['overall']:.2f}\")\n",
        "\n",
        "        # Show specific bias types and matches\n",
        "        for bias_type in engineer._bias_indicators.keys():\n",
        "            if analysis['bias'][bias_type] > 0:\n",
        "                print(f\"  - {bias_type}: {analysis['bias'][bias_type]:.2f}\")\n",
        "                print(f\"    Matches: {analysis['bias'][f'{bias_type}_matches']}\")\n",
        "\n",
        "    # Test evaluation with multiple criteria\n",
        "    for i, text in enumerate(texts):\n",
        "        print(f\"\\nEvaluating text {i+1} with multiple criteria:\")\n",
        "        scores = engineer.evaluate_text(text, [\"bias\", \"clarity\", \"engagement\", \"sentiment\"])\n",
        "        for criterion, score in scores.items():\n",
        "            print(f\"  - {criterion}: {score:.2f}\")\n",
        "\n",
        "# Run the test\n",
        "test_nltk_bias_detection()"
      ],
      "metadata": {
        "id": "iaOKSl4Sy5EO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ5fzWCffPrx"
      },
      "source": [
        "# Best Practices for Prompt Engineering\n",
        "1. Clarity and Structure\n",
        "\n",
        "- Use clear, specific instructions\n",
        "- Break down complex tasks into smaller components\n",
        "- Provide context and constraints explicitly\n",
        "\n",
        "2. Inclusivity and Neutrality\n",
        "\n",
        "- Use gender-neutral language\n",
        "- Consider diverse perspectives and experiences\n",
        "- Avoid cultural assumptions\n",
        "- Use accessible examples\n",
        "\n",
        "3. Technical Considerations\n",
        "\n",
        "- Specify output format requirements\n",
        "- Include error handling expectations\n",
        "- Define success criteria\n",
        "- Consider edge cases\n",
        "\n",
        "4. Response Evaluation\n",
        "\n",
        "- Define clear evaluation metrics\n",
        "- Check for bias in responses\n",
        "- Validate technical accuracy\n",
        "- Ensure accessibility of explanations\n",
        "\n",
        "# Common Pitfalls to Avoid\n",
        "\n",
        "1. Ambiguous instructions\n",
        "2. Implicit assumptions\n",
        "3. Lack of context\n",
        "4. Overly complex prompts\n",
        "5. Insufficient constraints\n",
        "6. Missing evaluation criteria\n",
        "\n",
        "# Next Steps\n",
        "\n",
        "- Experiment with different prompt structures\n",
        "- Test with various models\n",
        "- Gather feedback from diverse users\n",
        "- Iterate based on evaluation results\n",
        "- Document successful patterns\n",
        "- Build a prompt template library"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "f57ffd79f07881f90ffd84d1ee449596c2bc3e88fee236dc006178dc960802e5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}